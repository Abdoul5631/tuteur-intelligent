#!/usr/bin/env python
"""
Test du service IA avec historique de conversation
Valide que l'IA r√©pond dynamiquement selon le contexte
"""

import django
import os
import sys
import json
from datetime import datetime

os.environ.setdefault('DJANGO_SETTINGS_MODULE', 'backend.settings')
django.setup()

from core.services.llm_service import get_llm_service

# Initialiser le service IA en mode mock
llm_service = get_llm_service("mock")

print("=" * 80)
print("ü§ñ TEST: IA P√âDAGOGIQUE AVEC HISTORIQUE DE CONVERSATION")
print("=" * 80)
print()

# ============ TEST 1: R√©ponse √† "Bonjour" ============
print("üìù TEST 1: √âl√®ve √©crit 'Bonjour'")
print("-" * 80)

response1 = llm_service.chat_tuteur(
    message="Bonjour",
    niveau="4eme",
    matiere="mathematiques",
    conversation_history=[
        {"role": "user", "content": "Bonjour"}
    ]
)

print(f"üì§ Message: 'Bonjour'")
print(f"üì• R√©ponse IA:\n{response1.get('reponse', 'N/A')}")
print(f"   Type: {response1.get('type', 'N/A')}")
print()

# ============ TEST 2: √âl√®ve r√©pond "oui" SANS contexte ============
print("üìù TEST 2: √âl√®ve √©crit 'oui' SANS historique (ancien comportement)")
print("-" * 80)

response2_old = llm_service.chat_tuteur(
    message="oui",
    niveau="4eme",
    matiere="mathematiques",
    conversation_history=[
        {"role": "user", "content": "oui"}
    ]
)

print(f"üì§ Message: 'oui' (SANS historique)")
print(f"üì• R√©ponse IA:\n{response2_old.get('reponse', 'N/A')}")
print(f"   Type: {response2_old.get('type', 'N/A')}")
print()

# ============ TEST 3: √âl√®ve r√©pond "oui" AVEC historique ============
print("üìù TEST 3: √âl√®ve √©crit 'oui' AVEC historique (nouveau comportement ‚ú®)")
print("-" * 80)

response2_new = llm_service.chat_tuteur(
    message="oui",
    niveau="4eme",
    matiere="mathematiques",
    conversation_history=[
        {"role": "user", "content": "Bonjour"},
        {"role": "assistant", "content": "Salut! Bienvenue! Je suis ton tuteur en math√©matiques. Je suis l√† pour t'aider √† mieux comprendre. Qu'est-ce que tu aimerais apprendre ou dont tu as besoin d'aide?"},
        {"role": "user", "content": "Tu peux m'aider avec les exercices?"},
        {"role": "assistant", "content": "Bien s√ªr! Veux-tu que je te propose des exercices pour pratiquer?"},
        {"role": "user", "content": "oui"}
    ]
)

print(f"üì§ Message: 'oui'")
print(f"üì§ Contexte: Apr√®s une demande d'aide avec les exercices")
print(f"üì• R√©ponse IA:\n{response2_new.get('reponse', 'N/A')}")
print(f"   Type: {response2_new.get('type', 'N/A')}")
if 'exercices' in response2_new:
    print(f"   ‚úÖ Exercices g√©n√©r√©s: {len(response2_new.get('exercices', []))} exercices")
print()

# ============ TEST 4: R√©ponse "non" avec historique ============
print("üìù TEST 4: √âl√®ve √©crit 'non' quand demande d'exercices")
print("-" * 80)

response3 = llm_service.chat_tuteur(
    message="non",
    niveau="4eme",
    matiere="mathematiques",
    conversation_history=[
        {"role": "user", "content": "Bonjour"},
        {"role": "assistant", "content": "Salut! Bienvenue! Je suis ton tuteur..."},
        {"role": "user", "content": "Tu peux m'aider avec les exercices?"},
        {"role": "assistant", "content": "Bien s√ªr! Veux-tu que je te propose des exercices?"},
        {"role": "user", "content": "non"}
    ]
)

print(f"üì§ Message: 'non'")
print(f"üì• R√©ponse IA:\n{response3.get('reponse', 'N/A')}")
print(f"   Type: {response3.get('type', 'N/A')}")
print()

# ============ COMPARAISON ============
print("=" * 80)
print("‚úÖ ANALYSE COMPARATIVE")
print("=" * 80)

print("\n1Ô∏è‚É£ COMPARAISON: 'oui' SANS vs AVEC contexte")
print("-" * 80)
print(f"SANS contexte:\n  ‚Üí {response2_old.get('reponse', 'N/A')[:100]}...\n")
print(f"AVEC contexte:\n  ‚Üí {response2_new.get('reponse', 'N/A')[:100]}...")

if response2_old.get('reponse') == response2_new.get('reponse'):
    print("\n‚ùå PROBL√àME: Les r√©ponses sont IDENTIQUES (ancien bug)")
else:
    print("\n‚úÖ SUCC√àS: Les r√©ponses sont DIFF√âRENTES selon le contexte!")

if 'exercices' in response2_new:
    print("‚úÖ Les exercices sont g√©n√©r√©s quand l'utilisateur dit 'oui' en r√©ponse √† une question d'exercices")
else:
    print("‚ùå Les exercices ne sont pas g√©n√©r√©s")

print("\n2Ô∏è‚É£ DIFF√âRENCE: 'oui' vs 'non'")
print("-" * 80)
print(f"'oui' ‚Üí G√©n√®re exercices: {'exercices' in response2_new}")
print(f"'non' ‚Üí Propose alternatives: {'D\'accord!' in response3.get('reponse', '')}")

print("\n" + "=" * 80)
print("‚ú® R√âSULTAT FINAL")
print("=" * 80)

success = (
    'oui' in response2_new.get('reponse', '').lower() and
    ('exercices' in response2_new or 'exercice' in response2_new.get('reponse', '').lower()) and
    'accord' in response3.get('reponse', '').lower()
)

if success:
    print("‚úÖ L'IA FONCTIONNE MAINTENANT COMME UNE VRAIE IA P√âDAGOGIQUE!")
    print("   - Elle comprend le contexte de la conversation")
    print("   - Elle ne r√©p√®te pas les m√™mes r√©ponses")
    print("   - Elle adapte ses propositions selon l'historique")
else:
    print("‚ö†Ô∏è Il y a encore des probl√®mes √† corriger")

print()
